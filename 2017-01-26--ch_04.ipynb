{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match searches with bookings\n",
    "\n",
    "- For every search in the searches file, find out whether the search ended up in a booking or not (using the info in the bookings file). For instance, search and booking origin and destination should match. \n",
    "\n",
    "- For the bookings file, origin and destination are the columns dep_port and arr_port, respectively. \n",
    "\n",
    "- Generate a CSV file with the search data, and an additional field, containing 1 if the search ended up in a booking, and 0 otherwise.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggestion: follow the below plan of action:\n",
    "\n",
    "* Get familiar with the data\n",
    "* Select columns of interest\n",
    "* Decide what to do with NaNs\n",
    "\n",
    "* Make processing plan\n",
    "* Develop code that works with a sample\n",
    "\n",
    "* Adjust the code to work with Big data\n",
    "* Test big data approach on a sample\n",
    "\n",
    "* Run program with big data\n",
    "\n",
    "You can skip the first step this time, since you already did it for the other exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Prepare the data for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookings_path = '../../../data/Challenge/bookings.csv.bz2'\n",
    "searches_path = '../../../data/Challenge/searches.csv.bz2'\n",
    "\n",
    "bookings_small_sample = pd.read_csv(bookings_path, sep='^', nrows=100)\n",
    "searches_small_sample = pd.read_csv(searches_path, sep='^', nrows=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take small samples in order to determine column types. This is a bit risky because it can fail if the types don't fit the rest of the columns but it lets us save some memory, because pandas won't scan the whole file to determine types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookings_types = bookings_small_sample.dtypes.to_dict()\n",
    "\n",
    "bookings_sample = pd.read_csv(bookings_path, sep='^', nrows=10000, dtype=bookings_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['act_date           ', 'source', 'pos_ctry', 'pos_iata', 'pos_oid  ',\n",
       "       'rloc          ', 'cre_date           ', 'duration', 'distance',\n",
       "       'dep_port', 'dep_city', 'dep_ctry', 'arr_port', 'arr_city', 'arr_ctry',\n",
       "       'lst_port', 'lst_city', 'lst_ctry', 'brd_port', 'brd_city', 'brd_ctry',\n",
       "       'off_port', 'off_city', 'off_ctry', 'mkt_port', 'mkt_city', 'mkt_ctry',\n",
       "       'intl', 'route          ', 'carrier', 'bkg_class', 'cab_class',\n",
       "       'brd_time           ', 'off_time           ', 'pax', 'year', 'month',\n",
       "       'oid      '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use_bookings = ['cre_date           ', 'dep_port', 'arr_port']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Time', 'TxnCode', 'OfficeID', 'Country', 'Origin',\n",
       "       'Destination', 'RoundTrip', 'NbSegments', 'Seg1Departure',\n",
       "       'Seg1Arrival', 'Seg1Date', 'Seg1Carrier', 'Seg1BookingCode',\n",
       "       'Seg2Departure', 'Seg2Arrival', 'Seg2Date', 'Seg2Carrier',\n",
       "       'Seg2BookingCode', 'Seg3Departure', 'Seg3Arrival', 'Seg3Date',\n",
       "       'Seg3Carrier', 'Seg3BookingCode', 'Seg4Departure', 'Seg4Arrival',\n",
       "       'Seg4Date', 'Seg4Carrier', 'Seg4BookingCode', 'Seg5Departure',\n",
       "       'Seg5Arrival', 'Seg5Date', 'Seg5Carrier', 'Seg5BookingCode',\n",
       "       'Seg6Departure', 'Seg6Arrival', 'Seg6Date', 'Seg6Carrier',\n",
       "       'Seg6BookingCode', 'From', 'IsPublishedForNeg', 'IsFromInternet',\n",
       "       'IsFromVista', 'TerminalID', 'InternetOffice'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches_small_sample.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works fine with the bookings file, but not with the searches file. That's because there are some empty columns in the first few records that have strings in later records. Pandas will infer a `float64` type when it sees an empty column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stackoverflow.com/questions/24251219/pandas-read-csv-low-memory-and-dtype-options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'JNB'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas/_libs/parsers.c:15254)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot cast array from dtype('O') to dtype('float64') according to the rule 'safe'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-02a23221b457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                               \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'^'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearches_small_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                               nrows=10000)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11343)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:12175)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data (pandas/_libs/parsers.c:14136)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens (pandas/_libs/parsers.c:15330)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'JNB'"
     ]
    }
   ],
   "source": [
    "bookings_sample = pd.read_csv(bookings_path, \n",
    "                              sep='^', \n",
    "                              nrows=10000, \n",
    "                              dtype=bookings_small_sample.dtypes.to_dict(),\n",
    "                              usecols=cols_to_use_bookings)\n",
    "\n",
    "\n",
    "searches_sample = pd.read_csv(searches_path, \n",
    "                              sep='^',\n",
    "                              dtype=searches_small_sample.dtypes.to_dict(),\n",
    "                              nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                  object\n",
       "Time                  object\n",
       "TxnCode               object\n",
       "OfficeID              object\n",
       "Country               object\n",
       "Origin                object\n",
       "Destination           object\n",
       "RoundTrip              int64\n",
       "NbSegments             int64\n",
       "Seg1Departure         object\n",
       "Seg1Arrival           object\n",
       "Seg1Date              object\n",
       "Seg1Carrier           object\n",
       "Seg1BookingCode       object\n",
       "Seg2Departure         object\n",
       "Seg2Arrival           object\n",
       "Seg2Date              object\n",
       "Seg2Carrier           object\n",
       "Seg2BookingCode       object\n",
       "Seg3Departure         object\n",
       "Seg3Arrival           object\n",
       "Seg3Date              object\n",
       "Seg3Carrier           object\n",
       "Seg3BookingCode       object\n",
       "Seg4Departure         object\n",
       "Seg4Arrival           object\n",
       "Seg4Date              object\n",
       "Seg4Carrier           object\n",
       "Seg4BookingCode       object\n",
       "Seg5Departure        float64\n",
       "Seg5Arrival          float64\n",
       "Seg5Date             float64\n",
       "Seg5Carrier          float64\n",
       "Seg5BookingCode      float64\n",
       "Seg6Departure        float64\n",
       "Seg6Arrival          float64\n",
       "Seg6Date             float64\n",
       "Seg6Carrier          float64\n",
       "Seg6BookingCode      float64\n",
       "From                  object\n",
       "IsPublishedForNeg      int64\n",
       "IsFromInternet         int64\n",
       "IsFromVista            int64\n",
       "TerminalID            object\n",
       "InternetOffice        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches_small_sample.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookings_sample = pd.read_csv(bookings_path, \n",
    "                              sep='^', \n",
    "                              nrows=10000, \n",
    "                              dtype=bookings_small_sample.dtypes.to_dict(),\n",
    "                              usecols=cols_to_use_bookings)\n",
    "\n",
    "\n",
    "searches_sample = pd.read_csv(searches_path, \n",
    "                              sep='^',\n",
    "                              nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>...</th>\n",
       "      <th>Seg6Arrival</th>\n",
       "      <th>Seg6Date</th>\n",
       "      <th>Seg6Carrier</th>\n",
       "      <th>Seg6BookingCode</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>TXL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10:15:33</td>\n",
       "      <td>MPT</td>\n",
       "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
       "      <td>MD</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ATH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>KIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>18:04:49</td>\n",
       "      <td>MPT</td>\n",
       "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
       "      <td>US</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ICT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:42:40</td>\n",
       "      <td>FXP</td>\n",
       "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
       "      <td>SE</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RNB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>STO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:48:29</td>\n",
       "      <td>MPT</td>\n",
       "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
       "      <td>NO</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>OSL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>OSL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time TxnCode                          OfficeID Country  \\\n",
       "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
       "1  2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02      MD   \n",
       "2  2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3      US   \n",
       "3  2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b      SE   \n",
       "4  2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118      NO   \n",
       "\n",
       "  Origin Destination  RoundTrip  NbSegments Seg1Departure      ...        \\\n",
       "0    TXL         AUH          1           2           TXL      ...         \n",
       "1    ATH         MIL          0           1           ATH      ...         \n",
       "2    ICT         SFO          1           2           ICT      ...         \n",
       "3    RNB         ARN          0           1           RNB      ...         \n",
       "4    OSL         MAD          1           2           OSL      ...         \n",
       "\n",
       "  Seg6Arrival Seg6Date Seg6Carrier Seg6BookingCode    From IsPublishedForNeg  \\\n",
       "0         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "1         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "2         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "3         NaN      NaN         NaN             NaN    1ASI                 0   \n",
       "4         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "\n",
       "  IsFromInternet IsFromVista                        TerminalID InternetOffice  \n",
       "0              0           0  d41d8cd98f00b204e9800998ecf8427e            FRA  \n",
       "1              0           0  d41d8cd98f00b204e9800998ecf8427e            KIV  \n",
       "2              0           0  d41d8cd98f00b204e9800998ecf8427e            NYC  \n",
       "3              0           0  d41d8cd98f00b204e9800998ecf8427e            STO  \n",
       "4              0           0  d41d8cd98f00b204e9800998ecf8427e            OSL  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We didnt check for duplicates so far... What if the file is has duplicated lines?\n",
    "\n",
    "The bookings file can be reduced a lot for our purpose here. There are not that many combinations of origin, destination, and creation date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(334877, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookings = pd.read_csv(bookings_path, \n",
    "                              sep='^', \n",
    "                              dtype=bookings_small_sample.dtypes.to_dict(),\n",
    "                              usecols=cols_to_use_bookings)\n",
    "\n",
    "deduped_bookings = bookings.drop_duplicates()\n",
    "deduped_bookings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have seen that we have white space in some columns....\n",
    "\n",
    "Careful with this kind of thing!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cre_date', 'dep_port', 'arr_port'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_bookings.columns = deduped_bookings.columns.str.strip()\n",
    "deduped_bookings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LHR     ', 'CLT     ', 'SVO     ', ..., 'VEL     ', 'SLM     ',\n",
       "       'SG      '], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_bookings['arr_port'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Could we do this with command line?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Make processing plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target: generate a CSV file with the search data, and an additional field, containing 1 if the search ended up in a booking, and 0 otherwise.\n",
    "\n",
    "1) remove duplicates\n",
    "\n",
    "2) remove whitespaces\n",
    "\n",
    "    a) from colum names\n",
    "    \n",
    "    b) from content\n",
    "\n",
    "4) remove NaN\n",
    "\n",
    "5) define the model\n",
    "    if there is one booking for a given O&D done at the same day as the search (for a given O&D), ALL searches of the day (for a given 0&D) might have resulted from the same source and will be set with 1.\n",
    "    This is regardless of the boarding time of the plane... So if I was looking for plane for the first 4 days of December for a given O&D all those searches would be set to 1 not just the one correspoding to the correct boarding time\n",
    "\n",
    "        match\n",
    "        Search : [search_date, O&D] \n",
    "        Booking: [Activity_date, O&D]\n",
    "\n",
    "6) execute the model\n",
    "\n",
    "    a) Dedup bookings on [Activity_date, O&D] so that we dont have duplicates (and we can have number of bookings for the day), or we can just drop the duplicates\n",
    "    \n",
    "    b) search left join bookings adding \"Booked\" column\n",
    "    \n",
    "    c) test if the merge was done right\n",
    "    \n",
    "    d) fill NaN of \"booked\" column with 0\n",
    "    \n",
    "    e) pull all values of booked column >1 to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cre_date</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>arr_port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-22 00:00:00</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>LHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>SAL</td>\n",
       "      <td>CLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26 00:00:00</td>\n",
       "      <td>AKL</td>\n",
       "      <td>SVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-03-20 00:00:00</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-03-25 00:00:00</td>\n",
       "      <td>NRT</td>\n",
       "      <td>SIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cre_date  dep_port  arr_port\n",
       "0  2013-02-22 00:00:00  ZRH       LHR     \n",
       "1  2013-03-26 00:00:00  SAL       CLT     \n",
       "3  2013-03-26 00:00:00  AKL       SVO     \n",
       "5  2013-03-20 00:00:00  DEN       LGA     \n",
       "7  2013-03-25 00:00:00  NRT       SIN     "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_bookings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>...</th>\n",
       "      <th>Seg6Arrival</th>\n",
       "      <th>Seg6Date</th>\n",
       "      <th>Seg6Carrier</th>\n",
       "      <th>Seg6BookingCode</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>TXL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10:15:33</td>\n",
       "      <td>MPT</td>\n",
       "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
       "      <td>MD</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ATH</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>KIV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>18:04:49</td>\n",
       "      <td>MPT</td>\n",
       "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
       "      <td>US</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ICT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:42:40</td>\n",
       "      <td>FXP</td>\n",
       "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
       "      <td>SE</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RNB</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>STO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:48:29</td>\n",
       "      <td>MPT</td>\n",
       "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
       "      <td>NO</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>OSL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>OSL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time TxnCode                          OfficeID Country  \\\n",
       "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
       "1  2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02      MD   \n",
       "2  2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3      US   \n",
       "3  2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b      SE   \n",
       "4  2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118      NO   \n",
       "\n",
       "  Origin Destination  RoundTrip  NbSegments Seg1Departure      ...        \\\n",
       "0    TXL         AUH          1           2           TXL      ...         \n",
       "1    ATH         MIL          0           1           ATH      ...         \n",
       "2    ICT         SFO          1           2           ICT      ...         \n",
       "3    RNB         ARN          0           1           RNB      ...         \n",
       "4    OSL         MAD          1           2           OSL      ...         \n",
       "\n",
       "  Seg6Arrival Seg6Date Seg6Carrier Seg6BookingCode    From IsPublishedForNeg  \\\n",
       "0         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "1         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "2         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "3         NaN      NaN         NaN             NaN    1ASI                 0   \n",
       "4         NaN      NaN         NaN             NaN  1ASIWS                 0   \n",
       "\n",
       "  IsFromInternet IsFromVista                        TerminalID InternetOffice  \n",
       "0              0           0  d41d8cd98f00b204e9800998ecf8427e            FRA  \n",
       "1              0           0  d41d8cd98f00b204e9800998ecf8427e            KIV  \n",
       "2              0           0  d41d8cd98f00b204e9800998ecf8427e            NYC  \n",
       "3              0           0  d41d8cd98f00b204e9800998ecf8427e            STO  \n",
       "4              0           0  d41d8cd98f00b204e9800998ecf8427e            OSL  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searches_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't match-> need to format. We use, once again, the .str attribute of the column of  interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cre_date</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>arr_port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>ZRH</td>\n",
       "      <td>LHR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>SAL</td>\n",
       "      <td>CLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-03-26</td>\n",
       "      <td>AKL</td>\n",
       "      <td>SVO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-03-20</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LGA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>NRT</td>\n",
       "      <td>SIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cre_date  dep_port  arr_port\n",
       "0  2013-02-22  ZRH       LHR     \n",
       "1  2013-03-26  SAL       CLT     \n",
       "3  2013-03-26  AKL       SVO     \n",
       "5  2013-03-20  DEN       LGA     \n",
       "7  2013-03-25  NRT       SIN     "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_bookings['cre_date'] = deduped_bookings['cre_date'].str[:10]\n",
    "deduped_bookings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean the whitespace we saw earlier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ZRH'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deduped_bookings['dep_port'] = deduped_bookings['dep_port'].str.strip()\n",
    "deduped_bookings['arr_port'] = deduped_bookings['arr_port'].str.strip()\n",
    "deduped_bookings.iloc[0]['dep_port']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and check whether we need to in the searches file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = searches_sample['Origin'].apply(len)\n",
    "lens.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another way to check:\n",
    "\n",
    "lens = searches_sample['Origin'].apply(len)\n",
    "np.all(lens == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = searches_sample['Destination'].apply(len)\n",
    "np.all(lens == 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to put a 'booked' column in the result after the join. We might as well create it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_bookings['booked'] = 1\n",
    "deduped_bookings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the join..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>TxnCode</th>\n",
       "      <th>OfficeID</th>\n",
       "      <th>Country</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>RoundTrip</th>\n",
       "      <th>NbSegments</th>\n",
       "      <th>Seg1Departure</th>\n",
       "      <th>...</th>\n",
       "      <th>From</th>\n",
       "      <th>IsPublishedForNeg</th>\n",
       "      <th>IsFromInternet</th>\n",
       "      <th>IsFromVista</th>\n",
       "      <th>TerminalID</th>\n",
       "      <th>InternetOffice</th>\n",
       "      <th>cre_date</th>\n",
       "      <th>dep_port</th>\n",
       "      <th>arr_port</th>\n",
       "      <th>booked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>20:25:57</td>\n",
       "      <td>MPT</td>\n",
       "      <td>624d8c3ac0b3a7ca03e3c167e0f48327</td>\n",
       "      <td>DE</td>\n",
       "      <td>TXL</td>\n",
       "      <td>AUH</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>TXL</td>\n",
       "      <td>...</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>FRA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>10:15:33</td>\n",
       "      <td>MPT</td>\n",
       "      <td>b0af35b31588dc4ab06d5cf2986e8e02</td>\n",
       "      <td>MD</td>\n",
       "      <td>ATH</td>\n",
       "      <td>MIL</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ATH</td>\n",
       "      <td>...</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>KIV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>18:04:49</td>\n",
       "      <td>MPT</td>\n",
       "      <td>3561a60621de06ab1badc8ca55699ef3</td>\n",
       "      <td>US</td>\n",
       "      <td>ICT</td>\n",
       "      <td>SFO</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>ICT</td>\n",
       "      <td>...</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:42:40</td>\n",
       "      <td>FXP</td>\n",
       "      <td>1864e5e8013d9414150e91d26b6a558b</td>\n",
       "      <td>SE</td>\n",
       "      <td>RNB</td>\n",
       "      <td>ARN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RNB</td>\n",
       "      <td>...</td>\n",
       "      <td>1ASI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>STO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>17:48:29</td>\n",
       "      <td>MPT</td>\n",
       "      <td>1ec336348f44207d2e0027dc3a68c118</td>\n",
       "      <td>NO</td>\n",
       "      <td>OSL</td>\n",
       "      <td>MAD</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>OSL</td>\n",
       "      <td>...</td>\n",
       "      <td>1ASIWS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d41d8cd98f00b204e9800998ecf8427e</td>\n",
       "      <td>OSL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time TxnCode                          OfficeID Country  \\\n",
       "0  2013-01-01  20:25:57     MPT  624d8c3ac0b3a7ca03e3c167e0f48327      DE   \n",
       "1  2013-01-01  10:15:33     MPT  b0af35b31588dc4ab06d5cf2986e8e02      MD   \n",
       "2  2013-01-01  18:04:49     MPT  3561a60621de06ab1badc8ca55699ef3      US   \n",
       "3  2013-01-01  17:42:40     FXP  1864e5e8013d9414150e91d26b6a558b      SE   \n",
       "4  2013-01-01  17:48:29     MPT  1ec336348f44207d2e0027dc3a68c118      NO   \n",
       "\n",
       "  Origin Destination  RoundTrip  NbSegments Seg1Departure  ...      From  \\\n",
       "0    TXL         AUH          1           2           TXL  ...    1ASIWS   \n",
       "1    ATH         MIL          0           1           ATH  ...    1ASIWS   \n",
       "2    ICT         SFO          1           2           ICT  ...    1ASIWS   \n",
       "3    RNB         ARN          0           1           RNB  ...      1ASI   \n",
       "4    OSL         MAD          1           2           OSL  ...    1ASIWS   \n",
       "\n",
       "  IsPublishedForNeg IsFromInternet IsFromVista  \\\n",
       "0                 0              0           0   \n",
       "1                 0              0           0   \n",
       "2                 0              0           0   \n",
       "3                 0              0           0   \n",
       "4                 0              0           0   \n",
       "\n",
       "                         TerminalID InternetOffice cre_date dep_port arr_port  \\\n",
       "0  d41d8cd98f00b204e9800998ecf8427e            FRA      NaN      NaN      NaN   \n",
       "1  d41d8cd98f00b204e9800998ecf8427e            KIV      NaN      NaN      NaN   \n",
       "2  d41d8cd98f00b204e9800998ecf8427e            NYC      NaN      NaN      NaN   \n",
       "3  d41d8cd98f00b204e9800998ecf8427e            STO      NaN      NaN      NaN   \n",
       "4  d41d8cd98f00b204e9800998ecf8427e            OSL      NaN      NaN      NaN   \n",
       "\n",
       "  booked  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  \n",
       "3    NaN  \n",
       "4    NaN  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = searches_sample.merge(deduped_bookings, \n",
    "                               left_on=['Origin', 'Destination', 'Date'], \n",
    "                               right_on=['dep_port', 'arr_port', 'cre_date'],\n",
    "                               how = 'left')\n",
    "\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the extra columns we got from the bookings file, which we don't care about, and fill the NaNs (not booked) with 0s, as per the wording in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "searches_matched = joined.drop(['cre_date', 'dep_port', 'arr_port'], axis=1)\n",
    "\n",
    "searches_matched['booked'][searches_matched['booked'].isnull()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "searches_matched['booked'] = searches_matched['booked'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put in a single cell the whole processing\n",
    "\n",
    "From the input files, with a sample of searches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Input variables\n",
    "bookings_path = '../../../data/Challenge/bookings.csv.bz2'\n",
    "searches_path = '../../../data/Challenge/searches.csv.bz2'\n",
    "\n",
    "# Check types\n",
    "bookings_small_sample = pd.read_csv(bookings_path, sep='^', nrows=100)\n",
    "bookings_types = bookings_small_sample.dtypes.to_dict()\n",
    "\n",
    "# Read in the bookings file\n",
    "cols_to_use_bookings = ['cre_date           ', 'dep_port', 'arr_port']\n",
    "bookings = pd.read_csv(bookings_path, \n",
    "                              sep='^', \n",
    "                              dtype=bookings_small_sample.dtypes.to_dict(),\n",
    "                              usecols=cols_to_use_bookings)\n",
    "\n",
    "# Clean up the dataframe\n",
    "deduped_bookings = bookings.drop_duplicates()\n",
    "deduped_bookings.columns = deduped_bookings.columns.str.strip()\n",
    "deduped_bookings['dep_port'] = deduped_bookings['dep_port'].str.strip()\n",
    "deduped_bookings['arr_port'] = deduped_bookings['arr_port'].str.strip()\n",
    "deduped_bookings['cre_date'] = deduped_bookings['cre_date'].str[:10]\n",
    "\n",
    "# Introduce dummy column\n",
    "deduped_bookings['booked'] = 1\n",
    "\n",
    "\n",
    "# Read searches file\n",
    "searches_sample = pd.read_csv(searches_path, \n",
    "                              sep='^',\n",
    "                              nrows=10000)\n",
    "\n",
    "# Join\n",
    "joined = searches_sample.merge(deduped_bookings, \n",
    "                               left_on=['Origin', 'Destination', 'Date'], \n",
    "                               right_on=['dep_port', 'arr_port', 'cre_date'],\n",
    "                               how = 'left')\n",
    "\n",
    "# Clean up the resulting dataframe\n",
    "searches_matched = joined.drop(['cre_date', 'dep_port', 'arr_port'], axis=1)\n",
    "searches_matched['booked'] = searches_matched['booked'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapt it to Big Data\n",
    "\n",
    "We can hold the reduced bookings file in memory, so we'll process it in one go: this saves us a LOT of processing time. \n",
    "\n",
    "The searches file however needs to be processed in chunks. In this case we are not going to reduce it, since we are required to write it back to disk. However, we can safely process it without using a lot of memory by _writing to disk each chunk as we generate it_. This way we don't need to hold more than one chunk in memory at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dani/anaconda3/envs/master-p3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (40,41,42,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-046298d757bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mchunk_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skipfooter not supported for iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'as_recarray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1748\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1749\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read (pandas/_libs/parsers.c:10862)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory (pandas/_libs/parsers.c:11343)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows (pandas/_libs/parsers.c:11884)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows (pandas/_libs/parsers.c:11755)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error (pandas/_libs/parsers.c:28589)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/bz2.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/master-p3/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                     \u001b[0mrawblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Input variables\n",
    "bookings_path = '../../../data/Challenge/bookings.csv.bz2'\n",
    "searches_path = '../../../data/Challenge/searches.csv.bz2'\n",
    "result_path = './searches.matched.csv.bz2'\n",
    "\n",
    "# Check types\n",
    "bookings_small_sample = pd.read_csv(bookings_path, sep='^', nrows=100)\n",
    "bookings_types = bookings_small_sample.dtypes.to_dict()\n",
    "\n",
    "# Read in the bookings file\n",
    "cols_to_use_bookings = ['cre_date           ', 'dep_port', 'arr_port']\n",
    "bookings = pd.read_csv(bookings_path, \n",
    "                              sep='^', \n",
    "                              dtype=bookings_small_sample.dtypes.to_dict(),\n",
    "                              usecols=cols_to_use_bookings)\n",
    "\n",
    "# Clean up the dataframe\n",
    "deduped_bookings = bookings.drop_duplicates()\n",
    "deduped_bookings.columns = deduped_bookings.columns.str.strip()\n",
    "deduped_bookings['dep_port'] = deduped_bookings['dep_port'].str.strip()\n",
    "deduped_bookings['arr_port'] = deduped_bookings['arr_port'].str.strip()\n",
    "deduped_bookings['cre_date'] = deduped_bookings['cre_date'].str[:10]\n",
    "\n",
    "# Introduce dummy column\n",
    "deduped_bookings['booked'] = 1\n",
    "\n",
    "\n",
    "# Read searches file\n",
    "chunks = pd.read_csv(searches_path, \n",
    "                              sep='^',\n",
    "                              chunksize=1000000)\n",
    "\n",
    "chunk_num = 0 \n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk_num)\n",
    "    \n",
    "    # Join\n",
    "    joined = chunk.merge(deduped_bookings, \n",
    "                           left_on=['Origin', 'Destination', 'Date'], \n",
    "                           right_on=['dep_port', 'arr_port', 'cre_date'],\n",
    "                           how = 'left')\n",
    "\n",
    "    # Clean up the resulting dataframe\n",
    "    searches_matched = joined.drop(['cre_date', 'dep_port', 'arr_port'], axis=1)\n",
    "    searches_matched['booked'] = searches_matched['booked'].fillna(0)\n",
    "    \n",
    "    # And write it to disk, using mode 'append' in order not to\n",
    "    # overwrite the result of the previous chunks.\n",
    "    # We need to make sure we only write the header once, using\n",
    "    # the header argument to to_csv.\n",
    "    searches_matched.to_csv(result_path, \n",
    "                            sep ='^', \n",
    "                            compression='bz2', \n",
    "                            mode='a', \n",
    "                            header=chunk_num==0,\n",
    "                            index=False)\n",
    "    \n",
    "    chunk_num+=1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
